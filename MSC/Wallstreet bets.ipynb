{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T10:58:45.531745Z",
     "start_time": "2021-05-19T10:58:26.218720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JustAnotherCogg\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/asad70/reddit-sentiment-analysis/blob/master/reddit-sentiment-analysis.py\n",
    "\n",
    "import praw\n",
    "from data import *\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from credentials import credentials\n",
    "\n",
    "client_id, client_secret,password, user_agent, username = credentials\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    password=password,\n",
    "    user_agent=user_agent,\n",
    "    username=username,\n",
    ")\n",
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T10:58:46.117891Z",
     "start_time": "2021-05-19T10:58:45.536169Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect(\"MSC.db\")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "connection = sqlite3.connect('MSC.db')\n",
    "cursor = connection.cursor()\n",
    "sql = (\"Select symbol from SP500_companies\")\n",
    "df = pd.read_sql_query(sql,connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T10:58:46.132032Z",
     "start_time": "2021-05-19T10:58:46.122213Z"
    }
   },
   "outputs": [],
   "source": [
    "us = df['Symbol'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T10:58:46.160419Z",
     "start_time": "2021-05-19T10:58:46.141585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'############################################################################'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''############################################################################'''\n",
    "# set the program parameters\n",
    "subs = ['wallstreetbets' ]     # sub-reddit to search\n",
    "post_flairs = {'Daily Discussion', 'Weekend Discussion', 'Discussion'}    # posts flairs to search || None flair is automatically considered\n",
    "goodAuth = {'AutoModerator'}   # authors whom comments are allowed more than once\n",
    "uniqueCmt = True                # allow one comment per author per symbol\n",
    "ignoreAuthP = {'example'}       # authors to ignore for posts \n",
    "ignoreAuthC = {'example'}       # authors to ignore for comment \n",
    "upvoteRatio = 0.70         # upvote ratio for post to be considered, 0.70 = 70%\n",
    "ups = 20       # define # of upvotes, post is considered if upvotes exceed this #\n",
    "limit = 500     # define the limit, comments 'replace more' limit\n",
    "upvotes = 2     # define # of upvotes, comment is considered if upvotes exceed this #\n",
    "picks = 10     # define # of picks here, prints as \"Top ## picks are:\"\n",
    "picks_ayz = 5   # define # of picks for sentiment analysis\n",
    "'''############################################################################'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:13:46.913118Z",
     "start_time": "2021-05-19T10:58:46.170368Z"
    }
   },
   "outputs": [],
   "source": [
    "posts, count, c_analyzed, tickers, titles, a_comments = 0, 0, 0, {}, [], {}\n",
    "cmt_auth = {}\n",
    "\n",
    "for sub in subs:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    hot_python = subreddit.hot()    # sorting posts by hot\n",
    "    # Extracting comments, symbols from subreddit\n",
    "    for submission in hot_python:\n",
    "        flair = submission.link_flair_text \n",
    "        author = submission.author.name         \n",
    "        \n",
    "        # checking: post upvote ratio # of upvotes, post flair, and author \n",
    "        if submission.upvote_ratio >= upvoteRatio and submission.ups > ups and (flair in post_flairs or flair is None) and author not in ignoreAuthP:   \n",
    "            submission.comment_sort = 'new'     \n",
    "            comments = submission.comments\n",
    "            titles.append(submission.title)\n",
    "            posts += 1\n",
    "            try: \n",
    "                submission.comments.replace_more(limit=limit)   \n",
    "                for comment in comments:\n",
    "                    # try except for deleted account?\n",
    "                    try: auth = comment.author.name\n",
    "                    except: pass\n",
    "                    c_analyzed += 1\n",
    "                    \n",
    "                    # checking: comment upvotes and author\n",
    "                    if comment.score > upvotes and auth not in ignoreAuthC:      \n",
    "                        split = comment.body.split(\" \")\n",
    "                        for word in split:\n",
    "                            word = word.replace(\"$\", \"\")        \n",
    "                            # upper = ticker, length of ticker <= 5, excluded words,                     \n",
    "                            if word.isupper() and len(word) <= 5 and word not in blacklist and word in us:\n",
    "                                \n",
    "                                # unique comments, try/except for key errors\n",
    "                                if uniqueCmt and auth not in goodAuth:\n",
    "                                    try: \n",
    "                                        if auth in cmt_auth[word]: break\n",
    "                                    except: pass\n",
    "                                    \n",
    "                                # counting tickers\n",
    "                                if word in tickers:\n",
    "                                    tickers[word] += 1\n",
    "                                    a_comments[word].append(comment.body)\n",
    "                                    cmt_auth[word].append(auth)\n",
    "                                    count += 1\n",
    "                                else:                               \n",
    "                                    tickers[word] = 1\n",
    "                                    cmt_auth[word] = [auth]\n",
    "                                    a_comments[word] = [comment.body]\n",
    "                                    count += 1   \n",
    "            except Exception as e: print(e)\n",
    "                \n",
    "# sorts the dictionary\n",
    "symbols = dict(sorted(tickers.items(), key=lambda item: item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:22:23.428572Z",
     "start_time": "2021-05-19T11:22:23.277161Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(symbols, orient='index').to_csv(\"WB_20210519.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T17:37:40.526779Z",
     "start_time": "2021-05-18T17:37:40.502519Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=today).set_index(pd.Index([i for i in range(0, len(symbols))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T17:35:40.552490Z",
     "start_time": "2021-05-18T17:35:40.538650Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(symbols, orient='index').reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:22:14.495942Z",
     "start_time": "2021-05-19T11:22:14.106645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze 17130 comments in 16 posts in 1 subreddits.\n",
      "\n",
      "Posts analyzed saved in titles\n",
      "\n",
      "10 most mentioned picks: \n",
      "TSLA: 186\n",
      "T: 51\n",
      "AAPL: 40\n",
      "AMD: 38\n",
      "F: 24\n",
      "VIAC: 22\n",
      "C: 11\n",
      "HD: 10\n",
      "DIS: 10\n",
      "MSFT: 7\n"
     ]
    }
   ],
   "source": [
    "# sorts the dictionary\n",
    "#symbols = dict(sorted(tickers.items(), key=lambda item: item[1], reverse = True))\n",
    "top_picks = list(symbols.keys())[0:picks]\n",
    "\n",
    "# print top picks\n",
    "print(\"analyze {c} comments in {p} posts in {s} subreddits.\\n\".format(c=c_analyzed, p=posts, s=len(subs)))\n",
    "print(\"Posts analyzed saved in titles\")\n",
    "#for i in titles: print(i)  # prints the title of the posts analyzed\n",
    "\n",
    "print(f\"\\n{picks} most mentioned picks: \")\n",
    "times = []\n",
    "top = []\n",
    "for i in top_picks:\n",
    "    print(f\"{i}: {symbols[i]}\")\n",
    "    times.append(symbols[i])\n",
    "    top.append(f\"{i}: {symbols[i]}\")\n",
    "   \n",
    "    \n",
    "# Applying Sentiment Analysis\n",
    "scores, s = {}, {}\n",
    " \n",
    "vader = SentimentIntensityAnalyzer()\n",
    "# adding custom words from data.py \n",
    "vader.lexicon.update(new_words)\n",
    "\n",
    "picks_sentiment = list(symbols.keys())[0:picks_ayz]\n",
    "\n",
    "\n",
    "for symbol in picks_sentiment:\n",
    "    stock_comments = a_comments[symbol]\n",
    "    for cmnt in stock_comments:\n",
    "        score = vader.polarity_scores(cmnt)\n",
    "        if symbol in s:\n",
    "            s[symbol][cmnt] = score\n",
    "        else:\n",
    "            s[symbol] = {cmnt:score}      \n",
    "        if symbol in scores:\n",
    "            for key, _ in score.items():\n",
    "                scores[symbol][key] += score[key]\n",
    "        else:\n",
    "            scores[symbol] = score\n",
    "            \n",
    "    # calculating avg.\n",
    "    for key in score:\n",
    "        scores[symbol][key] = scores[symbol][key] / symbols[symbol]\n",
    "        scores[symbol][key]  = \"{pol:.3f}\".format(pol=scores[symbol][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T16:43:17.756744Z",
     "start_time": "2021-05-18T16:43:17.745868Z"
    }
   },
   "outputs": [],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T16:40:52.819967Z",
     "start_time": "2021-05-18T16:40:52.159578Z"
    }
   },
   "outputs": [],
   "source": [
    "# printing sentiment analysis \n",
    "print(f\"\\nSentiment analysis of top {picks_ayz} picks:\")\n",
    "df = pd.DataFrame(scores)\n",
    "df.index = ['Bearish', 'Neutral', 'Bullish', 'Total/Compound']\n",
    "df = df.T\n",
    "print(df)\n",
    "\n",
    "# Date Visualization\n",
    "# most mentioned picks    \n",
    "squarify.plot(sizes=times, label=top, alpha=.7 )\n",
    "plt.axis('off')\n",
    "plt.title(f\"{picks} most mentioned picks\")\n",
    "plt.show()\n",
    "\n",
    "# Sentiment analysis\n",
    "df = df.astype(float)\n",
    "colors = ['red', 'springgreen', 'forestgreen', 'coral']\n",
    "df.plot(kind = 'bar', color=colors, title=f\"Sentiment analysis of top {picks_ayz} picks:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
